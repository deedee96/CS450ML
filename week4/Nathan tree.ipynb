{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self):\n",
    "        self.num_passes = 0\n",
    "        pass\n",
    "\n",
    "    def set_feature_names(self, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    def fit(self, data, target):\n",
    "        self.target = target\n",
    "        tree = self.make_tree(data, target, self.feature_names)\n",
    "\n",
    "        return DecisionTreeModel(tree, self.feature_names)\n",
    "\n",
    "    # Returns the most freqquent target\n",
    "    def most_frequent_target(self):\n",
    "        unique, pos = np.unique(self.target, return_inverse=True)\n",
    "        counts = np.bincount(pos)\n",
    "        maxpos = counts.argmax()\n",
    "        return self.target[maxpos]\n",
    "\n",
    "    def calc_entropy(self, p):\n",
    "        if p != 0:\n",
    "            return -p * np.log2(p)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def get_feature_values(self, data, feature):\n",
    "        # List the values that feature can take\n",
    "        values = []\n",
    "        if len(data) == 1 and data not in values:\n",
    "            values.append(data)\n",
    "        elif len(data) > 1:\n",
    "            for datapoint in data:\n",
    "                if len(datapoint) == 1 and datapoint[0] not in values:\n",
    "                    values.append(datapoint[0])\n",
    "                elif len(datapoint) > 1 and datapoint[feature] not in values:\n",
    "                    values.append(datapoint[feature])\n",
    "        return values\n",
    "\n",
    "    def calc_info_gain(self, data, target, feature):\n",
    "        gain = 0\n",
    "        nData = len(data)\n",
    "        values = self.get_feature_values(data, feature)\n",
    "        featureCounts = np.zeros(len(values))\n",
    "        entropy = np.zeros(len(values))\n",
    "        valueIndex = 0\n",
    "\n",
    "        # Find where those values appear in data[feature] and the corresponding target\n",
    "        for value in values:\n",
    "            dataIndex = 0\n",
    "            newClasses = []\n",
    "            for datapoint in data:\n",
    "                if len(datapoint) == 1 and datapoint == value:\n",
    "                    featureCounts[valueIndex] += 1\n",
    "                    newClasses.append(target[dataIndex])\n",
    "                elif len(datapoint) > 1 and datapoint[feature] == value:\n",
    "                    featureCounts[valueIndex] += 1\n",
    "                    newClasses.append(target[dataIndex])\n",
    "                dataIndex += 1\n",
    "\n",
    "            # Get the values in new targets\n",
    "            classValues = []\n",
    "            for aclass in newClasses:\n",
    "                if classValues.count(aclass) == 0:\n",
    "                    classValues.append(aclass)\n",
    "\n",
    "            classCounts = np.zeros(len(classValues))\n",
    "            classIndex = 0\n",
    "            for classValue in classValues:\n",
    "                for aclass in newClasses:\n",
    "                    if aclass == classValue:\n",
    "                        classCounts[classIndex] += 1\n",
    "\n",
    "                classIndex += 1\n",
    "\n",
    "            for classIndex in range(len(classValues)):\n",
    "                entropy[valueIndex] += self.calc_entropy(float(classCounts[classIndex]) / sum(classCounts))\n",
    "\n",
    "            gain += float(featureCounts[valueIndex] / nData * entropy[valueIndex])\n",
    "            valueIndex += 1\n",
    "\n",
    "        return gain\n",
    "\n",
    "    def make_tree(self, data, target, featureNames):\n",
    "        self.num_passes += 1\n",
    "        if self.num_passes % 100000 == 0:\n",
    "            print(str(self.num_passes) + \" passes\")\n",
    "        # Various initialisations suppressed\n",
    "        newData = np.array([])\n",
    "        newClasses = np.array([])\n",
    "        newNames = np.array([])\n",
    "        nData = len(data)\n",
    "        nFeatures = len(featureNames)\n",
    "\n",
    "        if isinstance(target, str):\n",
    "            return target\n",
    "\n",
    "        if len(set(target)) == 1:\n",
    "            return target[0]\n",
    "\n",
    "        if nData == 0 or nFeatures == 0 or len(np.unique(data)) == 1:\n",
    "            # Have reached an empty branch\n",
    "            if len(target) != 0:\n",
    "                target_set = set(target)\n",
    "                frequency = [0] * len(target_set)\n",
    "                index = 0\n",
    "                for value in target_set:\n",
    "                    frequency[index] = np.count_nonzero(target == value)\n",
    "                    index += 1\n",
    "\n",
    "                default = target[np.argmax(frequency)]\n",
    "            else:\n",
    "                default = self.most_frequent_target()\n",
    "\n",
    "            return default\n",
    "\n",
    "\n",
    "        else:\n",
    "            # Choose which feature is best\n",
    "            gain = np.zeros(nFeatures)\n",
    "            values = []\n",
    "            for feature in range(nFeatures):\n",
    "                gain[feature] = self.calc_info_gain(data, target, feature)\n",
    "                # Find possible feature values\n",
    "                values.extend(self.get_feature_values(data, feature))\n",
    "            if len(values) > 1:\n",
    "                values = set(values)\n",
    "            else:\n",
    "                values = values[0]\n",
    "\n",
    "            bestFeature = np.argmin(gain)\n",
    "            tree = {featureNames[bestFeature]: {}}  # Find the possible feature values\n",
    "            for value in values:\n",
    "                index = 0\n",
    "                # Find the datapoints with each feature value\n",
    "                for datapoint in data:\n",
    "                    if datapoint[bestFeature] == value:\n",
    "                        if bestFeature == 0:\n",
    "                            datapoint = datapoint[1:]\n",
    "                            newNames = featureNames[1:]\n",
    "                        elif bestFeature == nFeatures:\n",
    "                            datapoint = datapoint[:-1]\n",
    "                            newNames = featureNames[:-1]\n",
    "                        else:\n",
    "                            newDataPoint = datapoint[:bestFeature]\n",
    "                            newDataPoint = np.append(newDataPoint, datapoint[bestFeature + 1:])\n",
    "                            datapoint = newDataPoint\n",
    "                            newNames = featureNames[:bestFeature]\n",
    "                            newNames = np.hstack((newNames, featureNames[bestFeature + 1:]))\n",
    "\n",
    "                        if len(newData) == 0:\n",
    "                            newData = datapoint\n",
    "                        else:\n",
    "                            newData = np.vstack((newData, datapoint))\n",
    "\n",
    "                        if len(newClasses) == 0:\n",
    "                            newClasses = target[index]\n",
    "                        else:\n",
    "                            newClasses = np.append(newClasses, target[index])\n",
    "\n",
    "                    index += 1\n",
    "                 # Now recurse to the next level\n",
    "                subtree = self.make_tree(newData, newClasses, newNames)\n",
    "                # And on returning, add the subtree on to the tree\n",
    "                tree[featureNames[bestFeature]][value] = subtree\n",
    "            return tree\n",
    "\n",
    "\n",
    "class DecisionTreeModel:\n",
    "    def __init__(self, tree, feature_names):\n",
    "        self.tree = tree\n",
    "        self.model = []\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    def get_node(self, tree, row):\n",
    "        if isinstance(tree, str):\n",
    "            return tree\n",
    "\n",
    "        key = next(iter(tree))\n",
    "        key_index = np.where(self.feature_names == key)\n",
    "\n",
    "        node_value = row[key_index][0]\n",
    "        return self.get_node(tree[key][node_value], row)\n",
    "        #print(\"\\n\\nROW AT KEY INDEX\")\n",
    "        #print(row[key_index])\n",
    "        #print(\"KEY - \" + str(key))\n",
    "        #print(\"NODE - \" + str(node_value))\n",
    "        #if node_value in tree[key]:\n",
    "        #    print(tree[key][node_value])\n",
    "        #    print(\"TREE VALUES?\")\n",
    "        #    print(list(tree.values())[0])\n",
    "        #    return self.get_node(tree[key][node_value], row)\n",
    "        #else:\n",
    "        #    print(\"\\nTREE\")\n",
    "        #    print(tree)\n",
    "        #    print(\"TREE KEYS?\")\n",
    "        #    print(tree.keys())\n",
    "        #    exit(1)\n",
    "\n",
    "    def predict(self, data):\n",
    "        for row in data:\n",
    "            self.model.append(self.get_node(self.tree, row))\n",
    "\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import division\n",
    "head = ['class', 'handicapped-infants', 'water-project-cost-sharing', 'adoption-of-the-budget-resolution', 'physician-fee-freeze','el-salvador-aid','religious-groups-in-schools','anti-satellite-test-ban','aid-to-nicaraguan-contras','mx-missile','immigration','synfuels-corporation-cutback','education-spending','superfund-right-to-sue','crime','duty-free-exports', 'export-administration-act-south-africa']\n",
    "data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data\", header=None, names=head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureNames = data.columns.values[1:17]\n",
    "data.replace(\"?\",\"-\",inplace=True)\n",
    "featureNames = head[1:17]\n",
    "_values = data.values\n",
    "#targets\n",
    "Y = _values[:,0]\n",
    "#train data\n",
    "X = _values[:,1:17]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(target, actual): \n",
    "    count = 0\n",
    "    for i in xrange(len(target)):\n",
    "        if target[i] == actual[i]:\n",
    "            count += 1\n",
    "\n",
    "    accuracy = count / len(target) * 100\n",
    "    print \"Accuracy: \", accuracy, \"%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 passes\n",
      "200000 passes\n",
      "300000 passes\n",
      "400000 passes\n",
      "500000 passes\n",
      "600000 passes\n",
      "700000 passes\n",
      "800000 passes\n",
      "900000 passes\n",
      "1000000 passes\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-de41d19385ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtree_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-313221292505>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-313221292505>\u001b[0m in \u001b[0;36mget_node\u001b[0;34m(self, tree, row)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mkey_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mnode_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m#print(\"\\n\\nROW AT KEY INDEX\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.set_feature_names(featureNames)\n",
    "tree_model = tree.fit(X_train, y_train)\n",
    "\n",
    "target = tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
