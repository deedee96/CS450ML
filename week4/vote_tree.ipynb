{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "head = ['class', 'handicapped-infants', 'water-project-cost-sharing', 'adoption-of-the-budget-resolution', 'physician-fee-freeze','el-salvador-aid','religious-groups-in-schools','anti-satellite-test-ban','aid-to-nicaraguan-contras','mx-missile','immigration','synfuels-corporation-cutback','education-spending','superfund-right-to-sue','crime','duty-free-exports', 'export-administration-act-south-africa']\n",
    "data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data\", header=None, names=head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureNames = data.columns.values[1:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.replace(\"?\",\"-\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "featureNames = head[1:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_values = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#targets\n",
    "Y = _values[:,0]\n",
    "#train data\n",
    "X = _values[:,1:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class treeClassifier(): \n",
    "    def fit(self, X_train, y_train, names):\n",
    "        self.names = names\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        tree = self.make_tree(X_train, y_train, names)\n",
    "        return DecisionTreeModel(tree,names)\n",
    "    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        pass\n",
    "    \n",
    "    def calc_entropy(self,p):\n",
    "        if p!=0:\n",
    "            return -p * np.log2(p)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    \n",
    "    def get_values(self,dataset, feature):\n",
    "        values = []\n",
    "        for datapoint in dataset:\n",
    "            if datapoint[feature] not in values:\n",
    "                values.append(datapoint[feature])\n",
    "                \n",
    "        return values\n",
    "    \n",
    "    def cal_info_gain(self, data, classes, feature):\n",
    "        gain = 0\n",
    "        nData = len(data)\n",
    "        # List the values that feature can take\n",
    "        #print feature;\n",
    "        values = []\n",
    "        print data\n",
    "        for datapoint in data:\n",
    "            if datapoint[feature] not in values:\n",
    "                #print datapoint[feature]\n",
    "                values.append(datapoint[feature])\n",
    "                \n",
    "                \n",
    "        featureCounts = np.zeros(len(values))\n",
    "        entropy = np.zeros(len(values))\n",
    "        valueIndex = 0\n",
    "        \n",
    "        for value in values:\n",
    "            dataIndex = 0\n",
    "            newClasses = []\n",
    "            for datapoint in data:\n",
    "                if datapoint[feature] == value:\n",
    "                    featureCounts[valueIndex]+=1\n",
    "                    newClasses.append(classes[dataIndex])              \n",
    "                dataIndex +=1\n",
    "                \n",
    "                \n",
    "            classValues = []\n",
    "            for aclass in newClasses:\n",
    "                if classValues.count(aclass) == 0:\n",
    "                    classValues.append(aclass)\n",
    "            classCounts = np.zeros(len(classValues))\n",
    "            classIndex = 0\n",
    "            for classValue in classValues:\n",
    "                for aclass in newClasses:\n",
    "                    if aclass == classValue:\n",
    "                        classCounts[classIndex]+=1\n",
    "                classIndex +=1\n",
    "                    \n",
    "            for classIndex in range(len(classValues)):\n",
    "                entropy[valueIndex] += self.calc_entropy(float(classCounts[classIndex]))/sum(classCounts)\n",
    "                \n",
    "            gain += float(featureCounts[valueIndex]) / nData * entropy[valueIndex]\n",
    "            valueIndex += 1\n",
    "        return gain\n",
    "                \n",
    "    def most_frequent(self):\n",
    "        counts = np.zeros(len(self.y_train))\n",
    "        list_target = list(y_train)\n",
    "        for i in xrange(len(random)):\n",
    "            counts[i] = list_target.count(y_train[i])\n",
    "        return self.y_train[counts.argmax()]\n",
    "        \n",
    "    def make_tree(self, data, classes, featuresNames):    \n",
    "        newData = np.array([])\n",
    "        newClasses = np.array([])\n",
    "        newNames = np.array([])     \n",
    "        nData = len(data);\n",
    "        nFeatures = len(featuresNames);\n",
    "        \n",
    "        if isinstance(classes,str):\n",
    "            return classes\n",
    "        \n",
    "        if len(set(classes)) == 1:\n",
    "            return classes[0]       \n",
    "        \n",
    "        if nData == 0 or nFeatures == 0 or len(np.unique(data)):\n",
    "            if len(classes) != 0:\n",
    "                target_set = set(classes)\n",
    "                frequency = [0] * len(target_set)\n",
    "                index = 0\n",
    "                for value in target_set:\n",
    "                    frequency[index] = np.count_nonzero(classes == value)\n",
    "                    index += 1\n",
    "\n",
    "                default = classes[np.argmax(frequency)]\n",
    "            else:\n",
    "                default = self.most_frequent()\n",
    "\n",
    "            return default\n",
    "\n",
    "           \n",
    "        elif list(classes).count(classes[0]) == nData:\n",
    "            return classes[0]\n",
    "        else:\n",
    "            \n",
    "            values = []\n",
    "            gain = np.zeros(nFeatures)\n",
    "            for feature in range(nFeatures):\n",
    "                gain[feature] = self.cal_info_gain(data, classes,feature)\n",
    "                values.extend(self.get_values(data, feature))\n",
    "            if len(values) > 1:\n",
    "                values = set(values)\n",
    "            else:\n",
    "                values = values[0]\n",
    "            bestFeature = np.argmin(gain)\n",
    "            tree = {featuresNames[bestFeature]: {}}\n",
    "            \n",
    "            \n",
    "            for value in values:\n",
    "                index = 0;\n",
    "                for datapoint in data:\n",
    "                    if datapoint[bestFeature] == value:\n",
    "                        if bestFeature == 0:\n",
    "                            datapoint = datapoint[1:]\n",
    "                            newNames = featuresNames[1:]\n",
    "                        elif bestFeature == nFeatures:\n",
    "                            datapoint = datapoint[:-1]\n",
    "                            newNames = featuresNames[:-1]\n",
    "                        else:\n",
    "                            datapoint = datapoint[:bestFeature]\n",
    "                            datapoint = np.append(datapoint, datapoint[bestFeature+1:])\n",
    "                            newNames = featuresNames[:bestFeature]\n",
    "                            newNames.extend(featuresNames[bestFeature+1:])\n",
    "                        newData = np.append(newData, datapoint)\n",
    "                        newClasses = np.append(newClasses,classes[index])\n",
    "                    index +=1\n",
    "                \n",
    "            subtree = self.make_tree(newData,newClasses,newNames)\n",
    "            \n",
    "            tree[featuresNames[bestFeature][value]] = subtree\n",
    "        return tree\n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTreeModel:\n",
    "    def __init__(self, tree, feature_names):\n",
    "        self.tree = tree\n",
    "        self.model = []\n",
    "        self.feature_names = feature_names\n",
    "        \n",
    "        \n",
    "\n",
    "    def get_node(self, tree, row):\n",
    "        if isinstance(tree, str):\n",
    "            return tree\n",
    "\n",
    "        key = next(iter(tree))\n",
    "        key_index = np.where(self.feature_names == key)\n",
    "\n",
    "        node_value = row[key_index][0]\n",
    "        return self.get_node(tree[key][node_value], row)\n",
    "    \n",
    "    def predict(self, data):\n",
    "        for row in data:\n",
    "            self.model.append(self.get_node(self.tree, row))\n",
    "\n",
    "        return self.model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = treeClassifier()\n",
    "tree_model = tree.fit(X_train, y_train, featureNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(target, actual): \n",
    "    count = 0\n",
    "    for i in xrange(len(target)):\n",
    "        if target[i] == actual[i]:\n",
    "            count += 1\n",
    "\n",
    "    accuracy = count / len(target) * 100\n",
    "    print \"Accuracy: \", accuracy, \"%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  60.3053435115 %\n"
     ]
    }
   ],
   "source": [
    "accuracy(target, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names\n",
    "#featureNames\n",
    "train_target = np.array(pd.cut(y_train, 3, labels=['setosa', 'versicolor', 'virginica']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sepal_length = np.array(pd.cut(X_train[:,0], 3, labels=['good', 'medium','bad']))\n",
    "sepal_width = np.array(pd.cut(X_train[:,1], 3, labels=['good', 'medium','bad']))\n",
    "petal_length = np.array(pd.cut(X_train[:,2], 3, labels=['good', 'medium','bad']))\n",
    "petal_width = np.array(pd.cut(X_train[:,3], 3, labels=['good', 'medium','bad']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_train = np.column_stack((sepal_length, sepal_width, petal_length,petal_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_test = np.column_stack((np.array(pd.cut(X_test[:,0], 3, labels=['good', 'medium','bad'])),np.array(pd.cut(X_test[:,0], 3, labels=['good', 'medium','bad'])),np.array(pd.cut(X_test[:,0], 3, labels=['good', 'medium','bad'])),np.array(pd.cut(X_test[:,0], 3, labels=['good', 'medium','bad']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = treeClassifier()\n",
    "tree_model = tree.fit(binned_train,train_target, iris.feature_names)\n",
    "target = tree_model.predict(binned_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  40.0 %\n"
     ]
    }
   ],
   "source": [
    "accuracy(target, np.array(pd.cut(y_test, 3, labels=['setosa', 'versicolor', 'virginica'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor',\n",
       " 'versicolor']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
