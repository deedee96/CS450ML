{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "head = ['class', 'handicapped-infants', 'water-project-cost-sharing', 'adoption-of-the-budget-resolution', 'physician-fee-freeze','el-salvador-aid','religious-groups-in-schools','anti-satellite-test-ban','aid-to-nicaraguan-contras','mx-missile','immigration','synfuels-corporation-cutback','education-spending','superfund-right-to-sue','crime','duty-free-exports', 'export-administration-act-south-africa']\n",
    "data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data\", header=None, names=head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureNames = data.columns.values[1:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.replace(\"?\",\"-\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "featureNames = head[1:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_values = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#targets\n",
    "Y = _values[:,0]\n",
    "#train data\n",
    "X = _values[:,1:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class treeClassifier(): \n",
    "    def fit(self, X_train, y_train, names):\n",
    "        self.names = names\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        tree = self.make_tree(X_train, y_train, names)\n",
    "        return DecisionTreeModel(tree,names)\n",
    "    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        pass\n",
    "    \n",
    "    def calc_entropy(self,p):\n",
    "        if p!=0:\n",
    "            return -p * np.log2(p)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    \n",
    "    def get_values(self,dataset, feature):\n",
    "        values = []\n",
    "        for datapoint in dataset:\n",
    "            if datapoint[feature] not in values:\n",
    "                values.append(datapoint[feature])\n",
    "                \n",
    "        return values\n",
    "    \n",
    "    def cal_info_gain(self, data, classes, feature):\n",
    "        gain = 0\n",
    "        nData = len(data)\n",
    "        # List the values that feature can take\n",
    "        #print feature;\n",
    "        values = []\n",
    "        print data\n",
    "        for datapoint in data:\n",
    "            if datapoint[feature] not in values:\n",
    "                #print datapoint[feature]\n",
    "                values.append(datapoint[feature])\n",
    "                \n",
    "                \n",
    "        featureCounts = np.zeros(len(values))\n",
    "        entropy = np.zeros(len(values))\n",
    "        valueIndex = 0\n",
    "        \n",
    "        for value in values:\n",
    "            dataIndex = 0\n",
    "            newClasses = []\n",
    "            for datapoint in data:\n",
    "                if datapoint[feature] == value:\n",
    "                    featureCounts[valueIndex]+=1\n",
    "                    newClasses.append(classes[dataIndex])              \n",
    "                dataIndex +=1\n",
    "                \n",
    "                \n",
    "            classValues = []\n",
    "            for aclass in newClasses:\n",
    "                if classValues.count(aclass) == 0:\n",
    "                    classValues.append(aclass)\n",
    "            classCounts = np.zeros(len(classValues))\n",
    "            classIndex = 0\n",
    "            for classValue in classValues:\n",
    "                for aclass in newClasses:\n",
    "                    if aclass == classValue:\n",
    "                        classCounts[classIndex]+=1\n",
    "                classIndex +=1\n",
    "                    \n",
    "            for classIndex in range(len(classValues)):\n",
    "                entropy[valueIndex] += self.calc_entropy(float(classCounts[classIndex]))/sum(classCounts)\n",
    "                \n",
    "            gain += float(featureCounts[valueIndex]) / nData * entropy[valueIndex]\n",
    "            valueIndex += 1\n",
    "        return gain\n",
    "                \n",
    "    def most_frequent(self):\n",
    "        counts = np.zeros(len(self.y_train))\n",
    "        list_target = list(y_train)\n",
    "        for i in xrange(len(random)):\n",
    "            counts[i] = list_target.count(y_train[i])\n",
    "        return self.y_train[counts.argmax()]\n",
    "        \n",
    "    def make_tree(self, data, classes, featuresNames):    \n",
    "        newData = np.array([])\n",
    "        newClasses = np.array([])\n",
    "        newNames = np.array([])     \n",
    "        nData = len(data);\n",
    "        nFeatures = len(featuresNames);\n",
    "        \n",
    "        if isinstance(classes,str):\n",
    "            return classes\n",
    "        \n",
    "        if nData == 0 or nFeatures == 0 or len(np.unique(data)):\n",
    "            if len(classes) != 0:\n",
    "                target_set = set(classes)\n",
    "                frequency = [0] * len(target_set)\n",
    "                index = 0\n",
    "                for value in target_set:\n",
    "                    frequency[index] = np.count_nonzero(classes == value)\n",
    "                    index += 1\n",
    "\n",
    "                default = classes[np.argmax(frequency)]\n",
    "            else:\n",
    "                default = self.most_frequent()\n",
    "\n",
    "            return default\n",
    "\n",
    "           \n",
    "        elif list(classes).count(classes[0]) == nData:\n",
    "            return classes[0]\n",
    "        else:\n",
    "            \n",
    "            values = []\n",
    "            gain = np.zeros(nFeatures)\n",
    "            for feature in range(nFeatures):\n",
    "                g = self.cal_info_gain(data, classes,feature)\n",
    "                values.extend(self.get_values(data, feature))\n",
    "            bestFeature = np.argmin(gain)\n",
    "            tree = {featuresNames[bestFeature]: {}}\n",
    "            \n",
    "            \n",
    "            for value in values:\n",
    "                index = 0;\n",
    "                for datapoint in data:\n",
    "                    if datapoint[bestFeature] == value:\n",
    "                        if bestFeature == 0:\n",
    "                            datapoint = datapoint[1:]\n",
    "                            newNames = featuresNames[1:]\n",
    "                        elif bestFeature == nFeatures:\n",
    "                            datapoint = datapoint[:-1]\n",
    "                            newNames = featuresNames[:-1]\n",
    "                        else:\n",
    "                            datapoint = datapoint[:bestFeature]\n",
    "                            datapoint = np.append(datapoint, datapoint[bestFeature+1:])\n",
    "                            newNames = featuresNames[:bestFeature]\n",
    "                            newNames.extend(featuresNames[bestFeature+1:])\n",
    "                        newData = np.append(newData, datapoint)\n",
    "                        newClasses = np.append(newClasses,classes[index])\n",
    "                    index +=1\n",
    "                \n",
    "            subtree = self.make_tree(newData,newClasses,newNames)\n",
    "            \n",
    "            tree[featuresNames[bestFeature][value]] = subtree\n",
    "        return tree\n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTreeModel:\n",
    "    def __init__(self, tree, feature_names):\n",
    "        self.tree = tree\n",
    "        self.model = []\n",
    "        self.feature_names = feature_names\n",
    "        \n",
    "        \n",
    "\n",
    "    def get_node(self, tree, row):\n",
    "        if isinstance(tree, str):\n",
    "            return tree\n",
    "\n",
    "        key = next(iter(tree))\n",
    "        key_index = np.where(self.feature_names == key)\n",
    "\n",
    "        node_value = row[key_index][0]\n",
    "        return self.get_node(tree[key][node_value], row)\n",
    "    \n",
    "    def predict(self, data):\n",
    "        for row in data:\n",
    "            self.model.append(self.get_node(self.tree, row))\n",
    "\n",
    "        return self.model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = treeClassifier()\n",
    "tree_model = tree.fit(X_train, y_train, featureNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  57.2519083969 %\n"
     ]
    }
   ],
   "source": [
    "count = 0;\n",
    "for i in xrange(len(target)):\n",
    "    if target[i] == y_train[i]:\n",
    "        count += 1\n",
    "        \n",
    "accuracy = count / len(target) * 100\n",
    "print \"Accuracy: \", accuracy, \"%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This instance instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-394eb42a2f4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtree_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-144-13c0d1149c70>\u001b[0m in \u001b[0;36mvisualize_tree\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dt.dot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             export_graphviz(tree, out_file=f,\n\u001b[0;32m---> 28\u001b[0;31m                             feature_names=self.feature_names)\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"dot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-Tpng\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dt.dot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-o\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dt.png\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/haodang/anaconda2/lib/python2.7/site-packages/sklearn/tree/export.pyc\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mout_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%d -> %d ;\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tree_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0mown_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0mreturn_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/haodang/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This instance instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
